<!DOCTYPE html>
<html lang="es">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Neuroprosthetics & Robotics - Brain-computer interfaces and emotion-aware robotic systems">
  <meta name="author" content="Mikel Val">
  <title>Neuroprosthetics & Robotics | Mikel Val</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="plugins/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="plugins/themify/css/themify-icons.css">
  <link rel="stylesheet" href="plugins/animate-css/animate.css">
  <link rel="stylesheet" href="plugins/aos/aos.css">
  <link rel="stylesheet" href="css/style.css">
</head>

<body class="portfolio" id="top">

<nav class="navbar navbar-expand-lg bg-transprent py-4 fixed-top navigation" id="navbar">
	<div class="container">
	  <a class="navbar-brand" href="index.html">
	  	<h2 class="logo">Mikel Val</h2>
	  </a>
	  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExample09" aria-controls="navbarsExample09" aria-expanded="false" aria-label="Toggle navigation">
		<span class="ti-view-list"></span>
	  </button>
  
	  <div class="collapse navbar-collapse text-center" id="navbarsExample09">
			<ul class="navbar-nav mx-auto">
			  <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
			   <li class="nav-item"><a class="nav-link" href="index.html#about">About</a></li>
			   <li class="nav-item"><a class="nav-link" href="index.html#skillbar">Expertise</a></li>
			   <li class="nav-item"><a class="nav-link" href="index.html#service">Services</a></li>
			   <li class="nav-item"><a class="nav-link" href="index.html#contact">Contact</a></li>
			</ul>

		  	<ul class="list-inline mb-0 ml-lg-4 nav-social">
			  	<li class="list-inline-item"><a href="https://scholar.google.es/citations?user=PoviSYIAAAAJ&hl=es" target="_blank" title="Google Scholar"><i class="ti-book"></i></a></li>
			  	<li class="list-inline-item"><a href="https://www.linkedin.com/in/mikel-valencia-5138b1109/" target="_blank" title="LinkedIn"><i class="ti-linkedin"></i></a></li>
			  	<li class="list-inline-item"><a href="https://www.researchgate.net/profile/Mikel-Valencia" target="_blank" title="ResearchGate"><i class="ti-bookmark-alt"></i></a></li>
			  	<li class="list-inline-item"><a href="https://github.com/mikelval82" target="_blank" title="GitHub"><i class="ti-github"></i></a></li>
		  	</ul>
	  </div>
	</div>
</nav>

<section class="page-title">
  <div class="container">
    <div class="row justify-content-center">
      <div class="col-lg-8">
          <div class="page-title text-center">
             <p>Neurotechnology & AI</p>
              <h1>Neuroprosthetics & Robotics</h1>
          </div>
      </div>
    </div>
  </div>
</section>

<section class="section portfolio-single pt-0">
    <div class="container">
        <div class="row">
            <div class="col-lg-8">
                <div class="service-content">
                    <p class="lead mt-4 mb-5">Dise√±o y desarrollo de interfaces cerebro-computadora, pr√≥tesis visuales corticales y sistemas rob√≥ticos con inteligencia emocional.</p>

                    <div class="row">
                        <div class="col-lg-6 mb-4">
                            <h4 class="mb-3"><i class="ti-pulse mr-3 text-color"></i>Brain-Computer Interfaces</h4>
                            <p>Sistemas BCI que traducen se√±ales cerebrales en comandos para control de dispositivos y comunicaci√≥n asistiva.</p>
                        </div>
                        <div class="col-lg-6 mb-4">
                            <h4 class="mb-3"><i class="ti-eye mr-3 text-color"></i>Cortical Visual Prostheses</h4>
                            <p>Investigaci√≥n en pr√≥tesis visuales que estimulan directamente la corteza cerebral para restaurar percepci√≥n visual parcial.</p>
                            <p class="mt-2"><a href="https://www.youtube.com/watch?v=3vgE3Ij1pBo" target="_blank" class="text-color"><i class="ti-video-clapper mr-2"></i>Ver video del proyecto</a></p>
                        </div>
                        <div class="col-lg-6 mb-4">
                            <h4 class="mb-3"><i class="ti-heart mr-3 text-color"></i>Emotion-Aware Robotics</h4>
                            <p>Robots sociales capaces de reconocer y responder apropiadamente a estados emocionales humanos.</p>
                        </div>
                        <div class="col-lg-6 mb-4">
                            <h4 class="mb-3"><i class="ti-control-shuffle mr-3 text-color"></i>Adaptive Neuroprosthetics</h4>
                            <p>Sistemas prot√©sicos que aprenden y se adaptan a patrones neuronales individuales mediante machine learning.</p>
                        </div>
                    </div>

                    <h3 class="mt-5 mb-4">Proyectos Destacados</h3>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-3">üß† Sistema BCI para Control de Silla de Ruedas mediante P300</h5>
                        <p class="mb-2">Interface cerebro-computadora no invasiva que permite a personas con discapacidad motora severa controlar una silla de ruedas mediante se√±ales cerebrales P300.</p>
                        <ul class="list-unstyled">
                            <li><strong>Tecnolog√≠as:</strong> EEG (Emotiv EPOC+), Python, scikit-learn, ROS (Robot Operating System)</li>
                            <li><strong>Algoritmos:</strong> LDA classifier, xDAWN spatial filtering, P300 detection</li>
                            <li><strong>Precisi√≥n:</strong> 92% en selecci√≥n de comandos, latencia <2 segundos</li>
                            <li><strong>Validaci√≥n:</strong> Ensayos cl√≠nicos con 8 pacientes durante 6 meses</li>
                        </ul>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-3">üëÅÔ∏è Investigaci√≥n en Pr√≥tesis Visual Cortical - Proyecto Horizon Cyber-Vision</h5>
                        <p class="mb-2">Investigaci√≥n europea para desarrollo de implante cortical con 1000+ electrodos para restauraci√≥n visual en personas con ceguera adquirida. Enfoque cibern√©tico innovador para pr√≥tesis cortical visual.</p>
                        <ul class="list-unstyled">
                            <li><strong>Colaboraci√≥n:</strong> Consorcio de 7 universidades europeas + 3 hospitales</li>
                            <li><strong>Contribuci√≥n:</strong> Desarrollo de algoritmos de procesamiento de im√°genes y predicci√≥n de fosfenos</li>
                            <li><strong>Tecnolog√≠as:</strong> Deep Learning para optimizaci√≥n de patrones de estimulaci√≥n, simulaciones computacionales</li>
                            <li><strong>Financiaci√≥n:</strong> Horizon 2020 (‚Ç¨4.5M)</li>
                            <li><strong>Publicaciones:</strong> "Horizon cyber-vision: A cybernetic approach for a cortical visual prosthesis" (2022), "The Assessment of Activities of Daily Living Skills Using Visual Prosthesis" (2022)</li>
                        </ul>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-3">ü§ñ Interacci√≥n Emocional Humano-Robot con Se√±ales Fisiol√≥gicas</h5>
                        <p class="mb-2">Desarrollo de sistemas de HRI que utilizan se√±ales EEG y GSR para reconocimiento emocional en tiempo real y adaptaci√≥n del comportamiento rob√≥tico. Aplicaciones en rob√≥tica narrativa afectiva y terapia.</p>
                        <ul class="list-unstyled">
                            <li><strong>Plataforma:</strong> Robots sociales (NAO, otros), Python, ROS</li>
                            <li><strong>Se√±ales:</strong> EEG en tiempo real con eliminaci√≥n de artefactos optimizada, GSR para arousal</li>
                            <li><strong>IA:</strong> Algoritmos de estimaci√≥n emocional, rob√≥tica afectiva adaptativa</li>
                            <li><strong>Publicaciones:</strong> "Optimization of Real-Time EEG Artifact Removal and Emotion Estimation for Human-Robot Interaction Applications" (2019), "Affective Robot Story-telling Human-Robot Interaction"</li>
                            <li><strong>Tesis:</strong> "Emotional Human-Robot Interaction Using Physiological Signals"</li>
                        </ul>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-3">ü¶æ Pr√≥tesis de Mano Mioelectrica con Feedback T√°ctil</h5>
                        <p class="mb-2">Desarrollo de sistema de control de pr√≥tesis mediante se√±ales EMG con retroalimentaci√≥n sensorial no invasiva a trav√©s de estimulaci√≥n vibrot√°ctil.</p>
                        <ul class="list-unstyled">
                            <li><strong>Sensores:</strong> 8 canales EMG (Delsys Trigno), sensores de fuerza FSR</li>
                            <li><strong>Control:</strong> Clasificaci√≥n de patrones EMG mediante SVM y LDA, 12 gestos diferentes</li>
                            <li><strong>Feedback:</strong> Array de 16 actuadores vibrot√°ctiles para sensaci√≥n de presi√≥n</li>
                            <li><strong>Usabilidad:</strong> Tiempo de agarre <1.5s, tasa de √©xito >90% en tareas de manipulaci√≥n</li>
                        </ul>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-3">üéØ Sistema de Neurofeedback para Rehabilitaci√≥n Post-Ictus</h5>
                        <p class="mb-2">Plataforma de entrenamiento cerebral que utiliza se√±ales EEG en tiempo real para rehabilitaci√≥n de funci√≥n motora en pacientes con accidente cerebrovascular.</p>
                        <ul class="list-unstyled">
                            <li><strong>Tecnolog√≠a:</strong> EEG de 32 canales, motor imagery classification, Unity VR</li>
                            <li><strong>Protocolo:</strong> Detecci√≥n de ritmos sensoriomotores (SMR), feedback visual inmediato</li>
                            <li><strong>Gamificaci√≥n:</strong> Entorno VR motivador con ajuste autom√°tico de dificultad</li>
                            <li><strong>Evidencia:</strong> Estudio piloto con 25 pacientes mostrando mejora motora significativa</li>
                        </ul>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-3">üß¨ Control Rob√≥tico mediante Grafos de Conectividad Funcional en Cultivos Neuronales</h5>
                        <p class="mb-2">Investigaci√≥n pionera en neurociencia computacional que utiliza estimulaci√≥n tet√°nica de cultivos hipocampales para generar grafos de conectividad funcional aplicados al control rob√≥tico en tiempo real.</p>
                        <ul class="list-unstyled">
                            <li><strong>Enfoque:</strong> Interfaz cultivo neuronal-robot, estimulaci√≥n tet√°nica, an√°lisis de conectividad</li>
                            <li><strong>T√©cnicas:</strong> Micro-electrodos para registro y estimulaci√≥n, an√°lisis de grafos de conectividad funcional</li>
                            <li><strong>Aplicaci√≥n:</strong> Control rob√≥tico bioinspirado basado en patrones de actividad neuronal biol√≥gica</li>
                            <li><strong>Publicaci√≥n:</strong> "Functional connectivity graphs in hippocampal cultures using tetanic stimulation for real time robotic control" (2016)</li>
                        </ul>
                    </div>

                    <h3 class="mt-5 mb-4">Publicaciones Cient√≠ficas Destacadas</h3>

                    <div class="card bg-light border-left-primary p-4 mb-3">
                        <h6 class="mb-2"><i class="ti-bookmark mr-2 text-color"></i><strong>Neuropr√≥tesis Corticales</strong></h6>
                        <ul class="mb-0">
                            <li class="mb-2">
                                <strong>Val Calvo, M.</strong> et al. (2022). "Horizon cyber-vision: A cybernetic approach for a cortical visual prosthesis". 
                                <em>Publicaci√≥n sobre pr√≥tesis cortical visual.</em>
                            </li>
                            <li class="mb-2">
                                <strong>Val Calvo, M.</strong> et al. (2022). "The Assessment of Activities of Daily Living Skills Using Visual Prosthesis". 
                                <em>Evaluaci√≥n de habilidades cotidianas con pr√≥tesis visuales corticales.</em>
                            </li>
                            <li class="mb-2">
                                Trabajos relacionados con se√±al intracortical e interfaces neuronales para restauraci√≥n visual.
                            </li>
                        </ul>
                    </div>

                    <div class="card bg-light border-left-primary p-4 mb-3">
                        <h6 class="mb-2"><i class="ti-android mr-2 text-color"></i><strong>Rob√≥tica e Interacci√≥n Humano-Robot</strong></h6>
                        <ul class="mb-0">
                            <li class="mb-2">
                                <strong>Val Calvo, M.</strong> et al. (2019). "Optimization of Real-Time EEG Artifact Removal and Emotion Estimation for Human-Robot Interaction Applications". 
                                <em>Estimaci√≥n emocional en tiempo real para HRI.</em>
                            </li>
                            <li class="mb-2">
                                <strong>Val Calvo, M.</strong> "Affective Robot Story-telling Human-Robot Interaction". 
                                <em>Interacci√≥n emocional en rob√≥tica narrativa.</em>
                            </li>
                            <li class="mb-2">
                                <strong>Val Calvo, M.</strong> et al. (2016). "Functional connectivity graphs in hippocampal cultures using tetanic stimulation for real time robotic control". 
                                <em>Neurociencia computacional aplicada al control rob√≥tico.</em>
                            </li>
                            <li class="mb-2">
                                <strong>Tesis Doctoral:</strong> "Emotional Human-Robot Interaction Using Physiological Signals". 
                                <em>Integraci√≥n de rob√≥tica emocional con se√±ales fisiol√≥gicas (EEG, GSR).</em>
                            </li>
                        </ul>
                    </div>

                    <div class="alert alert-info" role="alert">
                        <i class="ti-info mr-2"></i>
                        <strong>Perfil de Investigaci√≥n:</strong> ~50 citas en Google Scholar con √©nfasis en IA aplicada a sistemas biol√≥gicos, 
                        rob√≥tica bioinspirada y neurociencia computacional. Colaboraciones con grupos internacionales de neuropr√≥tesis y HRI.
                    </div>

                    <h3 class="mt-5 mb-4">√Åreas de Investigaci√≥n</h3>
                    <div class="row">
                        <div class="col-lg-6">
                            <ul class="lead">
                                <li>Interfaces cerebro-computadora (invasivas y no invasivas)</li>
                                <li>Procesamiento de se√±ales EEG/ECoG en tiempo real</li>
                                <li>Algoritmos de decodificaci√≥n neural</li>
                            </ul>
                        </div>
                        <div class="col-lg-6">
                            <ul class="lead">
                                <li>Rob√≥tica social y afectiva</li>
                                <li>Sistemas de neurofeedback</li>
                                <li>Pr√≥tesis neurales adaptativas</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>

            <div class="col-lg-4">
                <div class="portfolio-sidebar mt-5 mt-lg-0">
                    <div class="card bg-gray p-4">
                        <h4 class="card-title text-center mb-4 pt-3">Informaci√≥n del Servicio</h4>

                        <ul class="list-unstyled">
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Especializaci√≥n:</strong>
                                <span>Neurotechnology</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Experiencia:</strong>
                                <span>10+ a√±os</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Publicaciones:</strong>
                                <span>7 papers</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Hardware:</strong>
                                <span>EEG, EMG, BCI</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Software:</strong>
                                <span>Python, ROS, Unity</span>
                            </li>
                            <li class="text-center mt-4">
                               <a href="index.html#contact" class="btn btn-main">Contactar</a>
                            </li>
                        </ul>
                    </div>

                    <div class="card bg-gray p-4 mt-4">
                        <h4 class="text-center mb-4">¬øTienes un proyecto en mente?</h4>
                         <a href="index.html#contact" class="btn btn-solid-border">Hablemos</a>
                    </div>

                    <div class="card bg-gray p-4 mt-4">
                        <h5 class="mb-3">Servicios Relacionados</h5>
                        <ul class="list-unstyled">
                            <li class="mb-2"><a href="service-vision.html">‚Üí Computer Vision & Biosignals</a></li>
                            <li class="mb-2"><a href="service-health.html">‚Üí Digital Health & AI</a></li>
                            <li class="mb-2"><a href="service-research.html">‚Üí Research & Consulting</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<footer class="footer border-top-1">
	<div class="container">
		<div class="row align-items-center text-center text-lg-left">
			<div class="col-lg-3">
				<h3 class="logo mb-4">Mikel Val</h3>
			</div>
			<div class="col-lg-5">
				<ul class="list-inline footer-socials">
					<li class="list-inline-item"><a href="https://scholar.google.es/citations?user=PoviSYIAAAAJ&hl=es" target="_blank" title="Google Scholar"><i class="ti-book"></i></a></li>
					<li class="list-inline-item"><a href="https://www.linkedin.com/in/mikel-valencia-5138b1109/" target="_blank" title="LinkedIn"><i class="ti-linkedin"></i></a></li>
					<li class="list-inline-item"><a href="https://www.researchgate.net/profile/Mikel-Valencia" target="_blank" title="ResearchGate"><i class="ti-bookmark-alt"></i></a></li>
					<li class="list-inline-item"><a href="https://github.com/mikelval82" target="_blank" title="GitHub"><i class="ti-github"></i></a></li>
				</ul>
			</div>
			<div class="col-lg-4">
				<p class="lead">&copy; 2025 Mikel Val. Senior Researcher at HUMAN-TECH Research Center</p>
				<a href="#top" class="backtop smoth-scroll"><i class="ti-angle-up"></i></a>
			</div>
		</div>
	</div>
</footer>

    <script src="plugins/jquery/jquery.min.js"></script>
    <script src="plugins/bootstrap/js/popper.js"></script>
    <script src="plugins/bootstrap/js/bootstrap.min.js"></script>
    <script src="plugins/aos/aos.js"></script>
    <script src="js/script.js"></script>

  </body>
</html>
