<!DOCTYPE html>
<html lang="es">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Neuroprosthetics & Robotics - Brain-computer interfaces and emotion-aware robotic systems">
  <meta name="author" content="Mikel Val">
  <title>Neuroprosthetics & Robotics | Mikel Val</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="plugins/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="plugins/themify/css/themify-icons.css">
  <link rel="stylesheet" href="plugins/animate-css/animate.css">
  <link rel="stylesheet" href="plugins/aos/aos.css">
  <link rel="stylesheet" href="css/style.css">
</head>

<body class="portfolio" id="top">

<nav class="navbar navbar-expand-lg bg-transprent py-4 fixed-top navigation" id="navbar">
	<div class="container">
	  <a class="navbar-brand" href="index.html">
	  	<h2 class="logo">Mikel Val</h2>
	  </a>
	  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExample09" aria-controls="navbarsExample09" aria-expanded="false" aria-label="Toggle navigation">
		<span class="ti-view-list"></span>
	  </button>
  
	  <div class="collapse navbar-collapse text-center" id="navbarsExample09">
			<ul class="navbar-nav mx-auto">
			  <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
			   <li class="nav-item"><a class="nav-link" href="index.html#about">About</a></li>
			   <li class="nav-item"><a class="nav-link" href="index.html#skillbar">Expertise</a></li>
			   <li class="nav-item"><a class="nav-link" href="index.html#service">Services</a></li>
			   <li class="nav-item"><a class="nav-link" href="index.html#contact">Contact</a></li>
			</ul>

		  	<ul class="list-inline mb-0 ml-lg-4 nav-social">
			  	<li class="list-inline-item"><a href="https://scholar.google.es/citations?user=PoviSYIAAAAJ&hl=es" target="_blank" title="Google Scholar"><i class="ti-book"></i></a></li>
			  	<li class="list-inline-item"><a href="https://www.linkedin.com/in/mikel-valencia-5138b1109/" target="_blank" title="LinkedIn"><i class="ti-linkedin"></i></a></li>
			  	<li class="list-inline-item"><a href="https://www.researchgate.net/profile/Mikel-Valencia" target="_blank" title="ResearchGate"><i class="ti-bookmark-alt"></i></a></li>
			  	<li class="list-inline-item"><a href="https://github.com/mikelval82" target="_blank" title="GitHub"><i class="ti-github"></i></a></li>
		  	</ul>
	  </div>
	</div>
</nav>

<section class="page-title">
  <div class="container">
    <div class="row justify-content-center">
      <div class="col-lg-8">
          <div class="page-title text-center">
             <p>Neurotechnology & AI</p>
              <h1>Neuroprosthetics & Robotics</h1>
          </div>
      </div>
    </div>
  </div>
</section>

<section class="section portfolio-single pt-0">
    <div class="container">
        <div class="row">
            <div class="col-lg-8">
                <div class="service-content">
                    <p class="lead mt-4 mb-5">Dise√±o y desarrollo de interfaces cerebro-computadora, pr√≥tesis visuales corticales y sistemas rob√≥ticos con inteligencia emocional.</p>

                    <div class="row">
                        <div class="col-lg-6 mb-4">
                            <h4 class="mb-3"><i class="ti-pulse mr-3 text-color"></i>Brain-Computer Interfaces</h4>
                            <p>Sistemas BCI que traducen se√±ales cerebrales en comandos para control de dispositivos y comunicaci√≥n asistiva.</p>
                        </div>
                        <div class="col-lg-6 mb-4">
                            <h4 class="mb-3"><i class="ti-eye mr-3 text-color"></i>Cortical Visual Prostheses</h4>
                            <p>Investigaci√≥n en pr√≥tesis visuales que estimulan directamente la corteza cerebral para restaurar percepci√≥n visual parcial.</p>
                            <p class="mt-2"><a href="https://www.youtube.com/watch?v=3vgE3Ij1pBo" target="_blank" class="text-color"><i class="ti-video-clapper mr-2"></i>Ver video del proyecto</a></p>
                        </div>
                        <div class="col-lg-6 mb-4">
                            <h4 class="mb-3"><i class="ti-heart mr-3 text-color"></i>Emotion-Aware Robotics</h4>
                            <p>Robots sociales capaces de reconocer y responder apropiadamente a estados emocionales humanos.</p>
                        </div>
                        <div class="col-lg-6 mb-4">
                            <h4 class="mb-3"><i class="ti-control-shuffle mr-3 text-color"></i>Adaptive Neuroprosthetics</h4>
                            <p>Sistemas prot√©sicos que aprenden y se adaptan a patrones neuronales individuales mediante machine learning.</p>
                        </div>
                    </div>

                    <h3 class="mt-5 mb-4">Featured Projects</h3>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-3">üëÅÔ∏è NeuraViPeR - Neural Active Visual Prosthetics for Restoring Function (H2020, 2020-2024)</h5>
                        <p class="mb-2"><strong>Institution:</strong> Universidad Miguel Hern√°ndez de Elche | <strong>Funding:</strong> ‚Ç¨4M Horizon 2020 European Commission</p>
                        <p class="mb-2">Development of next-generation active visual neuroprosthetics based on thousands of microelectrodes controlled by Deep Learning algorithms to restore vision in blind individuals. The project creates lightweight, portable systems stimulating large portions of visual cortex with flexible implants, minimising tissue damage whilst ensuring long-term durability.</p>
                        <ul class="list-unstyled">
                            <li><strong>Duration:</strong> 4 years (September 2020 - 2024)</li>
                            <li><strong>Innovation:</strong> Flexible cortical implants with thousands of microelectrodes, Deep Learning-driven stimulation pattern optimization, lightweight and portable neuroprosthetic system design</li>
                            <li><strong>Contribution:</strong> Algorithm development for image processing, phosphene prediction, real-time phase estimation for closed-loop stimulation, electrophysiological record cleaning using machine learning and knowledge graphs</li>
                            <li><strong>Technologies:</strong> Deep Learning (object detection, monocular depth estimation, edge detection), UMAP embedding, Louvain-Communities graph analysis, intracortical microelectrode arrays (Utah arrays), real-time EEG/ECoG signal processing</li>
                            <li><strong>Clinical Application:</strong> Visual cortex stimulation for restoring functional vision in acquired blindness, Activities of Daily Living assessment in blind volunteers with cortical implants</li>
                            <li><strong>Publications:</strong> 
                                <ul class="mt-2">
                                    <li><a href="https://dialnet.unirioja.es/servlet/articulo?codigo=8733712" target="_blank" class="text-color">"Horizon cyber-vision: A cybernetic approach for a cortical visual prosthesis" (2022)</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:5nxA0vEk-isC" target="_blank" class="text-color">"The Assessment of Activities of Daily Living Skills Using Visual Prosthesis" (2022)</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:M3ejUd6NZC8C" target="_blank" class="text-color">"A new environment for assessing orientation and mobility in persons with severe visual impairments"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:roLk4NBRz8UC" target="_blank" class="text-color">"Performance evaluation of a real-time phase estimation algorithm applied to intracortical signals from human visual cortex"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:L8Ckcad2t8MC" target="_blank" class="text-color">"Neuronal Waveform Classification in Multielectrode Recordings Using Machine Learning Techniques and Multidimensional Analysis"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:qUcmZB5y_30C" target="_blank" class="text-color">"Recruiting native visual representations in visual cortex for electrode array based vision restoration" (Contributed Talk)</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&cstart=20&pagesize=80&citation_for_view=PoviSYIAAAAJ:4TOpqqG69KYC" target="_blank" class="text-color">"Advantages of Bidirectional Cortical Visual Prostheses"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&cstart=20&pagesize=80&citation_for_view=PoviSYIAAAAJ:hC7cP41nSMkC" target="_blank" class="text-color">"Recruiting native representations for electrically induced perception in blind humans"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&cstart=20&pagesize=80&citation_for_view=PoviSYIAAAAJ:aqlVkmm33-oC" target="_blank" class="text-color">"Automating Electrophysiological Record Cleaning in Visual Cortical Neuroprostheses using Machine Learning Techniques applied to knowledge graphs"</a></li>
                                </ul>
                            </li>
                        </ul>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-3">ü§ñ Emotional Human-Robot Interaction with Physiological Signals</h5>
                        <p class="mb-2">Development of HRI systems utilising EEG and GSR signals for real-time emotional recognition and adaptive robotic behaviour. Aplicaciones en rob√≥tica narrativa afectiva y terapia.</p>
                        <ul class="list-unstyled">
                            <li><strong>Platform:</strong> Robots sociales (NAO, otros), Python, ROS</li>
                            <li><strong>Signals:</strong> EEG en tiempo real con eliminaci√≥n de artefactos optimizada, GSR para arousal</li>
                            <li><strong>IA:</strong> Algoritmos de estimaci√≥n emocional, rob√≥tica afectiva adaptativa</li>
                            <li><strong>Publications:</strong> 
                                <ul class="mt-2">
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:eQOLeE2rZwMC" target="_blank" class="text-color">"Optimization of Real-Time EEG Artifact Removal and Emotion Estimation for Human-Robot Interaction Applications" (2019)</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:ufrVoPGSRksC" target="_blank" class="text-color">"Affective Robot Story-telling Human-Robot Interaction: Exploratory Real-time Emotion Estimation Analysis using Facial Expressions and Physiological Signals"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:_FxGoFyzp5QC" target="_blank" class="text-color">"Real-time Facial Expression Recognition Using Smoothed Deep Neural Network Ensemble"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:WF5omc3nYNoC" target="_blank" class="text-color">"Real-Time Multi-Modal Estimation of Dynamically Evoked Emotions Using EEG, Heart Rate and Galvanic Skin Response"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:qjMakFHDy7sC" target="_blank" class="text-color">"On the Use of Lateralization for Lightweight and Accurate Methodology for EEG Real Time Emotion Estimation Using Gaussian-Process Classifier"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:W7OEmFMy1HYC" target="_blank" class="text-color">"Setting the Parameters for an Accurate EEG (Electroencephalography)-Based Emotion Recognition System"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:zYLM7Y9cAGgC" target="_blank" class="text-color">"A New Model for the Implementation of Positive and Negative Emotion Recognition"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&cstart=20&pagesize=80&citation_for_view=PoviSYIAAAAJ:UeHWp8X0CEIC" target="_blank" class="text-color">"Exploring the Physiological Basis of Emotional HRI Using a BCI Interface"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:Tyk-4Ss8FVUC" target="_blank" class="text-color">"Real-time Emotional Recognition for Sociable Robotics Based on Deep Neural Networks Ensemble"</a></li>
                                </ul>
                            </li>
                            <li><strong>Thesis:</strong> <a href="https://espacio-pre.uned.es/entities/publication/0e85194e-6187-4e8d-a34c-ca07e5880bd8/full" target="_blank" class="text-color">"Emotional Human-Robot Interaction Using Physiological Signals"</a></li>
                        </ul>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-3">üß¨ Robotic Control via Functional Connectivity Graphs in Neuronal Cultures</h5>
                        <p class="mb-2">Pioneering computational neuroscience research utilising tetanic stimulation of hippocampal cultures to generate functional connectivity graphs applied to real-time robotic control.</p>
                        <ul class="list-unstyled">
                            <li><strong>Approach:</strong> Interfaz cultivo neuronal-robot, estimulaci√≥n tet√°nica, an√°lisis de conectividad</li>
                            <li><strong>Techniques:</strong> Micro-electrodes for recording and stimulation, functional connectivity graph analysis</li>
                            <li><strong>Application:</strong> Bio-inspired robotic control based on biological neuronal activity patterns</li>
                            <li><strong>Publications:</strong> 
                                <ul class="mt-2">
                                    <li><a href="https://www.frontiersin.org/10.3389/conf.fnins.2016.93.00104/event_abstract" target="_blank" class="text-color">"Functional Connectivity Graphs in Hippocampal Cultures Using Tetanic Stimulation for Real Time Robotic Control" (2016)</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:Y0pCki6q_DkC" target="_blank" class="text-color">"Toward an Improvement of the Analysis of Neural Coding"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:IjCSPb-OGe4C" target="_blank" class="text-color">"Frequency Variation Analysis in Neuronal Cultures for Stimulus Response Characterization"</a></li>
                                </ul>
                            </li>
                        </ul>
                    </div>

                    <h3 class="mt-5 mb-4">Research Areas</h3>
                    <div class="row">
                        <div class="col-lg-6">
                            <ul class="lead">
                                <li>Brain-computer interfaces (invasive and non-invasive)</li>
                                <li>Real-time EEG/ECoG signal processing</li>
                                <li>Neural decoding algorithms</li>
                            </ul>
                        </div>
                        <div class="col-lg-6">
                            <ul class="lead">
                                <li>Rob√≥tica social y afectiva</li>
                                <li>Sistemas de neurofeedback</li>
                                <li>Pr√≥tesis neurales adaptativas</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>

            <div class="col-lg-4">
                <div class="portfolio-sidebar mt-5 mt-lg-0">
                    <div class="card bg-gray p-4">
                        <h4 class="card-title text-center mb-4 pt-3">Service Information</h4>

                        <ul class="list-unstyled">
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Specialisation:</strong>
                                <span>Neurotechnology</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Experience:</strong>
                                <span>10+ years</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Publications:</strong>
                                <span>7 papers</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Patentes:</strong>
                                <span>2 concedidas</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Premios:</strong>
                                <span>UPV Excellence 2025</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Hardware:</strong>
                                <span>EEG, EMG, BCI</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Software:</strong>
                                <span>Python, ROS</span>
                            </li>
                            <li class="text-center mt-4">
                               <a href="index.html#contact" class="btn btn-main">Contactar</a>
                            </li>
                        </ul>
                    </div>

                    <div class="card bg-gray p-4 mt-4">
                        <h4 class="text-center mb-4">¬øTienes un proyecto en mente?</h4>
                         <a href="index.html#contact" class="btn btn-solid-border">Hablemos</a>
                    </div>

                    <div class="card bg-gray p-4 mt-4">
                        <h5 class="mb-3">Servicios Relacionados</h5>
                        <ul class="list-unstyled">
                            <li class="mb-2"><a href="service-vision.html">‚Üí Computer Vision & Biosignals</a></li>
                            <li class="mb-2"><a href="service-health.html">‚Üí Digital Health & AI</a></li>
                            <li class="mb-2"><a href="service-research.html">‚Üí Research & Consulting</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<footer class="footer border-top-1">
	<div class="container">
		<div class="row align-items-center text-center text-lg-left">
			<div class="col-lg-3">
				<h3 class="logo mb-4">Mikel Val</h3>
			</div>
			<div class="col-lg-5">
				<ul class="list-inline footer-socials">
					<li class="list-inline-item"><a href="https://scholar.google.es/citations?user=PoviSYIAAAAJ&hl=es" target="_blank" title="Google Scholar"><i class="ti-book"></i></a></li>
					<li class="list-inline-item"><a href="https://www.linkedin.com/in/mikel-valencia-5138b1109/" target="_blank" title="LinkedIn"><i class="ti-linkedin"></i></a></li>
					<li class="list-inline-item"><a href="https://www.researchgate.net/profile/Mikel-Valencia" target="_blank" title="ResearchGate"><i class="ti-bookmark-alt"></i></a></li>
					<li class="list-inline-item"><a href="https://github.com/mikelval82" target="_blank" title="GitHub"><i class="ti-github"></i></a></li>
				</ul>
			</div>
			<div class="col-lg-4">
				<p class="lead">&copy; 2025 Mikel Val. Senior Researcher at HUMAN-TECH Research Center</p>
				<a href="#top" class="backtop smoth-scroll"><i class="ti-angle-up"></i></a>
			</div>
		</div>
	</div>
</footer>

    <script src="plugins/jquery/jquery.min.js"></script>
    <script src="plugins/bootstrap/js/popper.js"></script>
    <script src="plugins/bootstrap/js/bootstrap.min.js"></script>
    <script src="plugins/aos/aos.js"></script>
    <script src="js/script.js"></script>

  </body>
</html>
