<!DOCTYPE html>
<html lang="es">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Neuroprosthetics & Robotics - Brain-computer interfaces and emotion-aware robotic systems">
  <meta name="author" content="Mikel Val">
  <title>Neuroprosthetics & Robotics | Mikel Val</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="plugins/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="plugins/themify/css/themify-icons.css">
  <link rel="stylesheet" href="plugins/animate-css/animate.css">
  <link rel="stylesheet" href="plugins/aos/aos.css">
  <link rel="stylesheet" href="css/style.css">
</head>

<body class="portfolio" id="top">

<nav class="navbar navbar-expand-lg bg-transprent py-4 fixed-top navigation" id="navbar">
	<div class="container">
	  <a class="navbar-brand" href="index.html">
	  	<h2 class="logo">Mikel Val</h2>
	  </a>
	  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExample09" aria-controls="navbarsExample09" aria-expanded="false" aria-label="Toggle navigation">
		<span class="ti-view-list"></span>
	  </button>
  
	  <div class="collapse navbar-collapse text-center" id="navbarsExample09">
			<ul class="navbar-nav mx-auto">
			  <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
			   <li class="nav-item"><a class="nav-link" href="index.html#about">About</a></li>
			   <li class="nav-item"><a class="nav-link" href="index.html#skillbar">Expertise</a></li>
			   <li class="nav-item"><a class="nav-link" href="index.html#service">Services</a></li>
			   <li class="nav-item"><a class="nav-link" href="index.html#contact">Contact</a></li>
			</ul>

		  	<ul class="list-inline mb-0 ml-lg-4 nav-social">
			  	<li class="list-inline-item"><a href="https://scholar.google.es/citations?user=PoviSYIAAAAJ&hl=es" target="_blank" title="Google Scholar"><i class="ti-book"></i></a></li>
			  	<li class="list-inline-item"><a href="https://www.linkedin.com/in/mikel-valencia-5138b1109/" target="_blank" title="LinkedIn"><i class="ti-linkedin"></i></a></li>
			  	<li class="list-inline-item"><a href="https://www.researchgate.net/profile/Mikel-Valencia" target="_blank" title="ResearchGate"><i class="ti-bookmark-alt"></i></a></li>
			  	<li class="list-inline-item"><a href="https://github.com/mikelval82" target="_blank" title="GitHub"><i class="ti-github"></i></a></li>
		  	</ul>
	  </div>
	</div>
</nav>

<section class="page-title">
  <div class="container">
    <div class="row justify-content-center">
      <div class="col-lg-8">
          <div class="page-title text-center">
             <p>Neurotechnology & AI</p>
              <h1>Neuroprosthetics & Robotics</h1>
          </div>
      </div>
    </div>
  </div>
</section>

<section class="section portfolio-single pt-0">
    <div class="container">
        <div class="row">
            <div class="col-lg-8">
                <div class="service-content">
                    <p class="lead mt-4 mb-5">Dise√±o y desarrollo de interfaces cerebro-computadora, pr√≥tesis visuales corticales y sistemas rob√≥ticos con inteligencia emocional.</p>

                    <div class="row">
                        <div class="col-lg-6 mb-4">
                            <h4 class="mb-3"><i class="ti-pulse mr-3 text-color"></i>Brain-Computer Interfaces</h4>
                            <p>Sistemas BCI que traducen se√±ales cerebrales en comandos para control de dispositivos y comunicaci√≥n asistiva.</p>
                        </div>
                        <div class="col-lg-6 mb-4">
                            <h4 class="mb-3"><i class="ti-eye mr-3 text-color"></i>Cortical Visual Prostheses</h4>
                            <p>Investigaci√≥n en pr√≥tesis visuales que estimulan directamente la corteza cerebral para restaurar percepci√≥n visual parcial.</p>
                            <p class="mt-2"><a href="https://www.youtube.com/watch?v=3vgE3Ij1pBo" target="_blank" class="text-color"><i class="ti-video-clapper mr-2"></i>Ver video del proyecto</a></p>
                        </div>
                        <div class="col-lg-6 mb-4">
                            <h4 class="mb-3"><i class="ti-heart mr-3 text-color"></i>Emotion-Aware Robotics</h4>
                            <p>Robots sociales capaces de reconocer y responder apropiadamente a estados emocionales humanos.</p>
                        </div>
                        <div class="col-lg-6 mb-4">
                            <h4 class="mb-3"><i class="ti-control-shuffle mr-3 text-color"></i>Adaptive Neuroprosthetics</h4>
                            <p>Sistemas prot√©sicos que aprenden y se adaptan a patrones neuronales individuales mediante machine learning.</p>
                        </div>
                    </div>

                    <h3 class="mt-5 mb-4">Featured Projects</h3>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-3">üëÅÔ∏è NeuraViPeR - Neural Active Visual Prosthetics for Restoring Function (H2020, 2020-2024)</h5>
                        <p class="mb-2"><strong>Institution:</strong> Universidad Miguel Hern√°ndez de Elche | <strong>Funding:</strong> ‚Ç¨4M Horizon 2020 European Commission</p>
                        <p class="mb-2">Development of next-generation active visual neuroprosthetics based on thousands of microelectrodes controlled by Deep Learning algorithms to restore vision in blind individuals. The project creates lightweight, portable systems stimulating large portions of visual cortex with flexible implants, minimising tissue damage whilst ensuring long-term durability.</p>
                        <ul class="list-unstyled">
                            <li><strong>Duration:</strong> 4 years (September 2020 - 2024)</li>
                            <li><strong>Innovation:</strong> Flexible cortical implants with thousands of microelectrodes, Deep Learning-driven stimulation pattern optimization, lightweight and portable neuroprosthetic system design</li>
                            <li><strong>Contribution:</strong> Algorithm development for image processing, phosphene prediction, real-time phase estimation for closed-loop stimulation, electrophysiological record cleaning using machine learning and knowledge graphs</li>
                            <li><strong>Technologies:</strong> Deep Learning (object detection, monocular depth estimation, edge detection), UMAP embedding, Louvain-Communities graph analysis, intracortical microelectrode arrays (Utah arrays), real-time EEG/ECoG signal processing</li>
                            <li><strong>Clinical Application:</strong> Visual cortex stimulation for restoring functional vision in acquired blindness, Activities of Daily Living assessment in blind volunteers with cortical implants</li>
                            <li><strong>Publications:</strong> 
                                <ul class="mt-2">
                                    <li><a href="https://dialnet.unirioja.es/servlet/articulo?codigo=8733712" target="_blank" class="text-color">"Horizon cyber-vision: A cybernetic approach for a cortical visual prosthesis" (2022)</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:5nxA0vEk-isC" target="_blank" class="text-color">"The Assessment of Activities of Daily Living Skills Using Visual Prosthesis" (2022)</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:M3ejUd6NZC8C" target="_blank" class="text-color">"A new environment for assessing orientation and mobility in persons with severe visual impairments"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:roLk4NBRz8UC" target="_blank" class="text-color">"Performance evaluation of a real-time phase estimation algorithm applied to intracortical signals from human visual cortex"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:L8Ckcad2t8MC" target="_blank" class="text-color">"Neuronal Waveform Classification in Multielectrode Recordings Using Machine Learning Techniques and Multidimensional Analysis"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:qUcmZB5y_30C" target="_blank" class="text-color">"Recruiting native visual representations in visual cortex for electrode array based vision restoration" (Contributed Talk)</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&cstart=20&pagesize=80&citation_for_view=PoviSYIAAAAJ:4TOpqqG69KYC" target="_blank" class="text-color">"Advantages of Bidirectional Cortical Visual Prostheses"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&cstart=20&pagesize=80&citation_for_view=PoviSYIAAAAJ:hC7cP41nSMkC" target="_blank" class="text-color">"Recruiting native representations for electrically induced perception in blind humans"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&cstart=20&pagesize=80&citation_for_view=PoviSYIAAAAJ:aqlVkmm33-oC" target="_blank" class="text-color">"Automating Electrophysiological Record Cleaning in Visual Cortical Neuroprostheses using Machine Learning Techniques applied to knowledge graphs"</a></li>
                                </ul>
                            </li>
                        </ul>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-3">ü§ñ Emotional Human-Robot Interaction with Physiological Signals</h5>
                        <p class="mb-2">Development of HRI systems utilising EEG and GSR signals for real-time emotional recognition and adaptive robotic behaviour. Aplicaciones en rob√≥tica narrativa afectiva y terapia.</p>
                        <ul class="list-unstyled">
                            <li><strong>Platform:</strong> Robots sociales (NAO, otros), Python, ROS</li>
                            <li><strong>Signals:</strong> EEG en tiempo real con eliminaci√≥n de artefactos optimizada, GSR para arousal</li>
                            <li><strong>IA:</strong> Algoritmos de estimaci√≥n emocional, rob√≥tica afectiva adaptativa</li>
                            <li><strong>Publications:</strong> 
                                <ul class="mt-2">
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:eQOLeE2rZwMC" target="_blank" class="text-color">"Optimization of Real-Time EEG Artifact Removal and Emotion Estimation for Human-Robot Interaction Applications" (2019)</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:ufrVoPGSRksC" target="_blank" class="text-color">"Affective Robot Story-telling Human-Robot Interaction: Exploratory Real-time Emotion Estimation Analysis using Facial Expressions and Physiological Signals"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:_FxGoFyzp5QC" target="_blank" class="text-color">"Real-time Facial Expression Recognition Using Smoothed Deep Neural Network Ensemble"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:WF5omc3nYNoC" target="_blank" class="text-color">"Real-Time Multi-Modal Estimation of Dynamically Evoked Emotions Using EEG, Heart Rate and Galvanic Skin Response"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:qjMakFHDy7sC" target="_blank" class="text-color">"On the Use of Lateralization for Lightweight and Accurate Methodology for EEG Real Time Emotion Estimation Using Gaussian-Process Classifier"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:W7OEmFMy1HYC" target="_blank" class="text-color">"Setting the Parameters for an Accurate EEG (Electroencephalography)-Based Emotion Recognition System"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:zYLM7Y9cAGgC" target="_blank" class="text-color">"A New Model for the Implementation of Positive and Negative Emotion Recognition"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&cstart=20&pagesize=80&citation_for_view=PoviSYIAAAAJ:UeHWp8X0CEIC" target="_blank" class="text-color">"Exploring the Physiological Basis of Emotional HRI Using a BCI Interface"</a></li>
                                    <li><a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:Tyk-4Ss8FVUC" target="_blank" class="text-color">"Real-time Emotional Recognition for Sociable Robotics Based on Deep Neural Networks Ensemble"</a></li>
                                </ul>
                            </li>
                            <li><strong>Thesis:</strong> <a href="https://espacio-pre.uned.es/entities/publication/0e85194e-6187-4e8d-a34c-ca07e5880bd8/full" target="_blank" class="text-color">"Emotional Human-Robot Interaction Using Physiological Signals"</a></li>
                        </ul>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-3">üß¨ Robotic Control via Functional Connectivity Graphs in Neuronal Cultures</h5>
                        <p class="mb-2">Pioneering computational neuroscience research utilising tetanic stimulation of hippocampal cultures to generate functional connectivity graphs applied to real-time robotic control.</p>
                        <ul class="list-unstyled">
                            <li><strong>Approach:</strong> Interfaz cultivo neuronal-robot, estimulaci√≥n tet√°nica, an√°lisis de conectividad</li>
                            <li><strong>Techniques:</strong> Micro-electrodes for recording and stimulation, functional connectivity graph analysis</li>
                            <li><strong>Application:</strong> Bio-inspired robotic control based on biological neuronal activity patterns</li>
                            <li><strong>Publications:</strong> 
                                <ul class="mt-2">
                                    <li>"Functional Connectivity Graphs in Hippocampal Cultures Using Tetanic Stimulation for Real Time Robotic Control" (2016)</li>
                                    <li>"Toward an Improvement of the Analysis of Neural Coding"</li>
                                    <li>"Frequency Variation Analysis in Neuronal Cultures for Stimulus Response Characterization"</li>
                                </ul>
                            </li>
                        </ul>
                    </div>

                    <h3 class="mt-5 mb-4">Scientific Publications</h3>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-2">üìÑ Automating Electrophysiological Record Cleaning in Visual Cortical Neuroprostheses Using Machine Learning Techniques Applied to Knowledge Graphs</h5>
                        <p class="mb-2"><strong>Authors:</strong> <strong>Mikel Val-Calvo</strong>, Javier Alegre-Cort√©s, Rocio Lopez Peco, Cristina Soto Sanchez, Jesualdo Fern√°ndez-Breis, Eduardo Fern√°ndez Jover</p>
                        <p class="mb-2"><strong>Journal:</strong> IBRO Neuroscience Reports, Volume 15, Pages S804 (2023) | <strong>Publisher:</strong> Elsevier</p>
                        <p class="mb-2">Novel algorithm automating electrophysiological recording preprocessing in visual cortical neuroprostheses using machine learning and knowledge graphs. Combines UMAP embedding representation with Louvain-Communities graph analysis to automatically classify and clean artifact waveforms generated by electrical stimulation, eliminating researcher subjectivity bias in preprocessing.</p>
                        <a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&cstart=20&pagesize=80&citation_for_view=PoviSYIAAAAJ:aqlVkmm33-oC" target="_blank" class="text-color">
                            <i class="ti-link mr-2"></i>View publication ‚Üí
                        </a>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-2">üìÑ Advantages of Bidirectional Cortical Visual Prostheses</h5>
                        <p class="mb-2"><strong>Authors:</strong> Fabrizio Grani, <strong>Mikel Val-Calvo</strong>, Rocio Lopez Peco, Alfonso Rodil Doblado, Dorota Waclawczyk, Roberto Morollon Ruiz, Leili Soo, Cristina Soto Sanchez, Marcos Villamar√≠n Ortiz, Eduardo Fern√°ndez Jover</p>
                        <p class="mb-2"><strong>Journal:</strong> IBRO Neuroscience Reports, Volume 15, Pages S948-S949 (2023) | <strong>Publisher:</strong> Elsevier | <strong>Citations:</strong> 1</p>
                        <p class="mb-2">Analysis of bidirectional cortical visual prostheses exploring voluntary pulse signal (SPV) generation and control through EEG interfaces. The research investigates brain-machine connection devices, examining signal characteristics (amplitude, frequency, intensity) and their potential for enhancing brain-machine interfaces in visual prosthesis applications.</p>
                        <a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&cstart=20&pagesize=80&citation_for_view=PoviSYIAAAAJ:4TOpqqG69KYC" target="_blank" class="text-color">
                            <i class="ti-link mr-2"></i>View publication ‚Üí
                        </a>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-2">üìÑ The Assessment of Activities of Daily Living Skills Using Visual Prosthesis</h5>
                        <p class="mb-2"><strong>Authors:</strong> Dorota Waclawczyk, Leili Soo, <strong>Mikel Val-Calvo</strong>, Roberto Morollon Ruiz, Fabrizio Grani, Eduardo Fern√°ndez Jover</p>
                        <p class="mb-2"><strong>Conference:</strong> International Work-Conference on the Interplay Between Natural and Artificial Computation (2022) | <strong>Publisher:</strong> Springer, Cham | <strong>Citations:</strong> 2</p>
                        <p class="mb-2">Comprehensive review of functional assessment techniques for visual prosthesis, covering Activities of Daily Living evaluation and post-implantation training. The work addresses the need for standardized assessment methods enabling comparison between research groups, acknowledging that standard vision tests are insufficient for low-resolution prosthetic vision devices.</p>
                        <a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:5nxA0vEk-isC" target="_blank" class="text-color">
                            <i class="ti-link mr-2"></i>View publication ‚Üí
                        </a>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-2">üìÑ Recruiting Native Visual Representations in Visual Cortex for Electrode Array Based Vision Restoration</h5>
                        <p class="mb-2"><strong>Authors:</strong> Karol√≠na Korvasov√°, Fabrizio Grani, Matƒõj Vold≈ôich, Roc√≠o L√≥pez Peco, David Berling, <strong>Mikel Val Calvo</strong>, Alfonso Rodil Doblado, Tibor R√≥zsa, Cristina Soto S√°nchez, Xing Chen, Eduardo Fernandez, J√°n Antol√≠k</p>
                        <p class="mb-2"><strong>Journal:</strong> Journal of Vision, Volume 25, Issue 5, Pages 10-10 (2025) | <strong>Publisher:</strong> The Association for Research in Vision and Ophthalmology | <strong>Citations:</strong> 2</p>
                        <p class="mb-2">Novel method to infer orientation preference maps from spontaneous activity recorded with Utah arrays in visual cortex, enabling recruitment of native functional representations for cortical visual prosthetics. The approach was validated in detailed V1 models, macaque recordings, and applied to recordings from blind human volunteers with cortical visual prostheses, demonstrating preservation of both spatial and functional organization.</p>
                        <a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:qUcmZB5y_30C" target="_blank" class="text-color">
                            <i class="ti-link mr-2"></i>View publication ‚Üí
                        </a>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-2">üìÑ Neuronal Waveform Classification in Multielectrode Recordings Using Machine Learning Techniques and Multidimensional Analysis</h5>
                        <p class="mb-2"><strong>Authors:</strong> Roc√≠o L√≥pez-Peco, <strong>Mikel Val-Calvo</strong>, Cristina Soto-S√°nchez, Adri√°n Villamarin-Ortiz, Gloria Ruiz-Boix, Jos√© Manuel Ferr√°ndez-Vicente, Eduardo Fern√°ndez</p>
                        <p class="mb-2"><strong>Journal:</strong> International Journal of Neural Systems, Volume 35, Issue 6, Pages 2550031 (2025) | <strong>Citations:</strong> 2</p>
                        <p class="mb-2">Automatic spike waveform classifier using advanced machine learning techniques including UMAP (Uniform Manifold Approximation and Projection), Gaussian Mixture Model (GMM), and Random Forest. The classifier provides more precise neuronal waveform classification in multielectrode extracellular recordings, going beyond traditional trough-to-peak duration methods to capture the full diversity of cortical neurons and discharge patterns.</p>
                        <a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:L8Ckcad2t8MC" target="_blank" class="text-color">
                            <i class="ti-link mr-2"></i>View publication ‚Üí
                        </a>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-2">üìÑ Performance Evaluation of a Real-Time Phase Estimation Algorithm Applied to Intracortical Signals from Human Visual Cortex</h5>
                        <p class="mb-2"><strong>Authors:</strong> Fabrizio Grani, Cristina Soto-Sanchez, Alfonso Rodil Doblado, Maria Dolores Grima, Fernando Farfan, <strong>Mikel Val Calvo</strong>, Leili Soo, Dorota Waclawczyk, Jose Manuel Ferrandez, Pablo Gonzalez, Mar√≠a Dolores Coves, Arantxa Alfaro, Eduardo Fern√°ndez</p>
                        <p class="mb-2"><strong>Conference:</strong> International Work-Conference on the Interplay Between Natural and Artificial Computation, Pages 516-525 (2022) | <strong>Publisher:</strong> Springer International Publishing | <strong>Citations:</strong> 3</p>
                        <p class="mb-2">Evaluation of real-time phase estimator algorithm for closed-loop cortical visual prosthesis. The study demonstrates that closed-loop stimulation based on local field potential phase recorded with intracortical microelectrodes improves perception induction in blind human volunteers, with phase-dependent accuracy in human occipital cortex.</p>
                        <a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:roLk4NBRz8UC" target="_blank" class="text-color">
                            <i class="ti-link mr-2"></i>View publication ‚Üí
                        </a>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-2">üìÑ A New Environment for Assessing Orientation and Mobility in Persons with Severe Visual Impairments</h5>
                        <p class="mb-2"><strong>Authors:</strong> Roberto Morollon Ruiz, Leili Soo, <strong>Mikel Val-Calvo</strong>, Rocio L√≥pez-Peco, Fabrizio Grani, Dorota Waclawczyk, Alfonso Rodil Doblado, Cristina Soto Sanchez, Eduardo Fern√°ndez-Jover</p>
                        <p class="mb-2"><strong>Journal:</strong> IBRO Neuroscience Reports, Volume 15, Pages S950-S951 (2023) | <strong>Citations:</strong> 3</p>
                        <p class="mb-2">Virtual reality environment for evaluating orientation and mobility skills in individuals with severe visual impairments, integrating closed-loop imagery movement and brain-computer interface training methods for stroke rehabilitation applications.</p>
                        <a href="https://scholar.google.es/citations?view_op=view_citation&hl=es&user=PoviSYIAAAAJ&citation_for_view=PoviSYIAAAAJ:M3ejUd6NZC8C" target="_blank" class="text-color">
                            <i class="ti-link mr-2"></i>View publication ‚Üí
                        </a>
                    </div>

                    <div class="card bg-gray p-4 mb-4">
                        <h5 class="mb-2">üìÑ Horizon Cyber-vision: A Cybernetic Approach for a Cortical Visual Prosthesis</h5>
                        <p class="mb-2">Configurable wearable system for cortical visual prosthesis using Deep Learning (object detection, monocular depth estimation, edge detection) and eye-tracking.</p>
                        <a href="https://dialnet.unirioja.es/servlet/articulo?codigo=8733712" target="_blank" class="text-color">
                            <i class="ti-link mr-2"></i>View publication ‚Üí
                        </a>
                    </div>

                    <h3 class="mt-5 mb-4">Research Areas</h3>
                    <div class="row">
                        <div class="col-lg-6">
                            <ul class="lead">
                                <li>Brain-computer interfaces (invasive and non-invasive)</li>
                                <li>Real-time EEG/ECoG signal processing</li>
                                <li>Neural decoding algorithms</li>
                            </ul>
                        </div>
                        <div class="col-lg-6">
                            <ul class="lead">
                                <li>Rob√≥tica social y afectiva</li>
                                <li>Sistemas de neurofeedback</li>
                                <li>Pr√≥tesis neurales adaptativas</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>

            <div class="col-lg-4">
                <div class="portfolio-sidebar mt-5 mt-lg-0">
                    <div class="card bg-gray p-4">
                        <h4 class="card-title text-center mb-4 pt-3">Service Information</h4>

                        <ul class="list-unstyled">
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Specialisation:</strong>
                                <span>Neurotechnology</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Experience:</strong>
                                <span>10+ years</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Publications:</strong>
                                <span>7 papers</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Patentes:</strong>
                                <span>2 concedidas</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Premios:</strong>
                                <span>UPV Excellence 2025</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Hardware:</strong>
                                <span>EEG, EMG, BCI</span>
                            </li>
                            <li class="d-flex justify-content-between align-content-center mb-3">
                                <strong>Software:</strong>
                                <span>Python, ROS</span>
                            </li>
                            <li class="text-center mt-4">
                               <a href="index.html#contact" class="btn btn-main">Contactar</a>
                            </li>
                        </ul>
                    </div>

                    <div class="card bg-gray p-4 mt-4">
                        <h4 class="text-center mb-4">¬øTienes un proyecto en mente?</h4>
                         <a href="index.html#contact" class="btn btn-solid-border">Hablemos</a>
                    </div>

                    <div class="card bg-gray p-4 mt-4">
                        <h5 class="mb-3">Servicios Relacionados</h5>
                        <ul class="list-unstyled">
                            <li class="mb-2"><a href="service-vision.html">‚Üí Computer Vision & Biosignals</a></li>
                            <li class="mb-2"><a href="service-health.html">‚Üí Digital Health & AI</a></li>
                            <li class="mb-2"><a href="service-research.html">‚Üí Research & Consulting</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<footer class="footer border-top-1">
	<div class="container">
		<div class="row align-items-center text-center text-lg-left">
			<div class="col-lg-3">
				<h3 class="logo mb-4">Mikel Val</h3>
			</div>
			<div class="col-lg-5">
				<ul class="list-inline footer-socials">
					<li class="list-inline-item"><a href="https://scholar.google.es/citations?user=PoviSYIAAAAJ&hl=es" target="_blank" title="Google Scholar"><i class="ti-book"></i></a></li>
					<li class="list-inline-item"><a href="https://www.linkedin.com/in/mikel-valencia-5138b1109/" target="_blank" title="LinkedIn"><i class="ti-linkedin"></i></a></li>
					<li class="list-inline-item"><a href="https://www.researchgate.net/profile/Mikel-Valencia" target="_blank" title="ResearchGate"><i class="ti-bookmark-alt"></i></a></li>
					<li class="list-inline-item"><a href="https://github.com/mikelval82" target="_blank" title="GitHub"><i class="ti-github"></i></a></li>
				</ul>
			</div>
			<div class="col-lg-4">
				<p class="lead">&copy; 2025 Mikel Val. Senior Researcher at HUMAN-TECH Research Center</p>
				<a href="#top" class="backtop smoth-scroll"><i class="ti-angle-up"></i></a>
			</div>
		</div>
	</div>
</footer>

    <script src="plugins/jquery/jquery.min.js"></script>
    <script src="plugins/bootstrap/js/popper.js"></script>
    <script src="plugins/bootstrap/js/bootstrap.min.js"></script>
    <script src="plugins/aos/aos.js"></script>
    <script src="js/script.js"></script>

  </body>
</html>
